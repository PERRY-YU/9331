{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yCGZL364Nf3n"
   },
   "outputs": [],
   "source": [
    "CREATE TABLE Offices (\n",
    "    office_id INT PRIMARY KEY,\n",
    "    address VARCHAR(255),\n",
    "    city VARCHAR(100),\n",
    "    state VARCHAR(50),\n",
    "    zip_code VARCHAR(10),\n",
    "    phone_number VARCHAR(15)\n",
    ");\n",
    "\n",
    "CREATE TABLE Employees (\n",
    "    employee_id INT PRIMARY KEY,\n",
    "    first_name VARCHAR(100),\n",
    "    last_name VARCHAR(100),\n",
    "    email VARCHAR(100),\n",
    "    phone_number VARCHAR(15),\n",
    "    employment_type VARCHAR(50)\n",
    ");\n",
    "\n",
    "CREATE TABLE EmployeeRoles (\n",
    "    role_id INT PRIMARY KEY,\n",
    "    role_name VARCHAR(50),\n",
    "    description TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE EmployeeOfficeAssignments (\n",
    "    assignment_id INT PRIMARY KEY,\n",
    "    employee_id INT,\n",
    "    office_id INT,\n",
    "    start_date DATE,\n",
    "    end_date DATE,\n",
    "    FOREIGN KEY (employee_id) REFERENCES Employees(employee_id),\n",
    "    FOREIGN KEY (office_id) REFERENCES Offices(office_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE Expenses (\n",
    "    expense_id INT PRIMARY KEY,\n",
    "    description TEXT,\n",
    "    amount DECIMAL(10, 2),\n",
    "    date DATE,\n",
    "    office_id INT,\n",
    "    FOREIGN KEY (office_id) REFERENCES Offices(office_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE Owners (\n",
    "    owner_id INT PRIMARY KEY,\n",
    "    first_name VARCHAR(100),\n",
    "    last_name VARCHAR(100),\n",
    "    email VARCHAR(100),\n",
    "    phone_number VARCHAR(15)\n",
    ");\n",
    "\n",
    "CREATE TABLE Schools (\n",
    "    school_id INT PRIMARY KEY,\n",
    "    address VARCHAR(255),\n",
    "    city VARCHAR(100),\n",
    "    state VARCHAR(50),\n",
    "    zip_code VARCHAR(10)\n",
    ");\n",
    "\n",
    "CREATE TABLE Homes (\n",
    "    home_id INT PRIMARY KEY,\n",
    "\tschool_id INT,\n",
    "    address VARCHAR(255),\n",
    "    city VARCHAR(100),\n",
    "    state VARCHAR(50),\n",
    "\tdate_recorded DATE,\n",
    "    assessed_value DECIMAL(10,2),\n",
    "\tsale_amount DECIMAL(10,2),\n",
    "\tsales_ratio DECIMAL(10,4),\n",
    "    type VARCHAR(50),\n",
    "    status VARCHAR(50),\n",
    "\tFOREIGN KEY (school_id) REFERENCES Schools(school_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE HomeFeatures (\n",
    "    feature_id INT PRIMARY KEY,\n",
    "    feature_name VARCHAR(50),\n",
    "    description TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE HomeFeatureAssignments (\n",
    "    assignment_id INT PRIMARY KEY,\n",
    "    home_id INT,\n",
    "    feature_id INT,\n",
    "    FOREIGN KEY (home_id) REFERENCES Homes(home_id),\n",
    "    FOREIGN KEY (feature_id) REFERENCES HomeFeatures(feature_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE Clients (\n",
    "    client_id INT PRIMARY KEY,\n",
    "    first_name VARCHAR(100),\n",
    "    last_name VARCHAR(100),\n",
    "    email VARCHAR(100),\n",
    "    phone_number VARCHAR(15),\n",
    "    client_type VARCHAR(50)\n",
    ");\n",
    "\n",
    "CREATE TABLE ClientPreferences (\n",
    "    preference_id INT PRIMARY KEY,\n",
    "    client_id INT,\n",
    "    preference_type VARCHAR(50),\n",
    "    value VARCHAR(255),\n",
    "    FOREIGN KEY (client_id) REFERENCES Clients(client_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE TransactionsTypes (\n",
    "    transaction_type_id INT PRIMARY KEY,\n",
    "    transaction_type_name VARCHAR(50),\n",
    "    description TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE Transactions (\n",
    "    transaction_id INT PRIMARY KEY,\n",
    "    home_id INT,\n",
    "    buyer_id INT,\n",
    "\towner_id INT,\n",
    "    agent_id INT,\n",
    "    transaction_type_id INT,\n",
    "    date DATE,\n",
    "    amount DECIMAL(10, 2),\n",
    "    FOREIGN KEY (home_id) REFERENCES Homes(home_id),\n",
    "    FOREIGN KEY (buyer_id) REFERENCES Clients(client_id),\n",
    "    FOREIGN KEY (owner_id) REFERENCES Owners(owner_id),\n",
    "    FOREIGN KEY (agent_id) REFERENCES Employees(employee_id),\n",
    "    FOREIGN KEY (transaction_type_id) REFERENCES TransactionsTypes(transaction_type_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE PaymentMethods (\n",
    "    payment_method_id INT PRIMARY KEY,\n",
    "    method_name VARCHAR(50),\n",
    "    description TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE TransactionPayments (\n",
    "    payment_id INT PRIMARY KEY,\n",
    "    transaction_id INT,\n",
    "    payment_method_id INT,\n",
    "    amount DECIMAL(10, 2),\n",
    "    date DATE,\n",
    "    FOREIGN KEY (transaction_id) REFERENCES Transactions(transaction_id),\n",
    "    FOREIGN KEY (payment_method_id) REFERENCES PaymentMethods(payment_method_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE OpenHouses (\n",
    "    open_house_id INT PRIMARY KEY,\n",
    "    home_id INT,\n",
    "    date DATE,\n",
    "    start_time TIME,\n",
    "    end_time TIME,\n",
    "    FOREIGN KEY (home_id) REFERENCES Homes(home_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE Appointments (\n",
    "    appointment_id INT PRIMARY KEY,\n",
    "    client_id INT,\n",
    "    employee_id INT,\n",
    "    home_id INT,\n",
    "    date DATE,\n",
    "    time TIME,\n",
    "    FOREIGN KEY (client_id) REFERENCES Clients(client_id),\n",
    "    FOREIGN KEY (employee_id) REFERENCES Employees(employee_id),\n",
    "    FOREIGN KEY (home_id) REFERENCES Homes(home_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE MarketingCampaigns (\n",
    "    campaign_id INT PRIMARY KEY,\n",
    "    campaign_name VARCHAR(100),\n",
    "    description TEXT,\n",
    "    start_date DATE,\n",
    "    end_date DATE,\n",
    "    budget DECIMAL(10, 2)\n",
    ");\n",
    "\n",
    "CREATE TABLE CampaignResults (\n",
    "    result_id INT PRIMARY KEY,\n",
    "    campaign_id INT,\n",
    "    result_description TEXT,\n",
    "    result_date DATE,\n",
    "    FOREIGN KEY (campaign_id) REFERENCES MarketingCampaigns(campaign_id)\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "office： 5\n",
    "\n",
    "employee：20*5\n",
    "\n",
    "role: Associate-Senior-Manager\n",
    "\n",
    "Assignments: employee id-125\n",
    "\n",
    "Expenses: 1000+\n",
    "\n",
    "Owner:1000\n",
    "\n",
    "schools: 100\n",
    "\n",
    "homes:1000\n",
    "\n",
    "homefeature:50\n",
    "\n",
    "homefeature assignments:5000\n",
    "\n",
    "clients:1000\n",
    "\n",
    "client preferences:5*1000\n",
    "\n",
    "transactions:400\n",
    "\n",
    "transaction type:5\n",
    "\n",
    "payments:400\n",
    "\n",
    "paymentmethod：5\n",
    "\n",
    "openhouses: 100\n",
    "\n",
    "appooments:1000*5\n",
    "\n",
    "Marketing campagin:20\n",
    "\n",
    "Campagin results:20\n",
    "\n"
   ],
   "metadata": {
    "id": "s-R9jJz5CwQT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "_xghj8VVDSdH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#### Homes\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#import dataset\n",
    "df = pd.read_csv('Real_Estate_Sales_2001-2020_GL.csv', low_memory = False)\n",
    "df.head()\n",
    "\n",
    "#data exploration\n",
    "df.info()\n",
    "print(\"The total NA value in Date Recorded: \", df['Date Recorded'].isna().sum())  # check NA values\n",
    "print(\"The total NA value in Address: \", df['Address'].isna().sum())\n",
    "print(\"The total NA value in Residential Type: \", df['Residential Type'].isna().sum())\n",
    "\n",
    "#drop NA values\n",
    "df = df.dropna(subset=['Residential Type'])\n",
    "df = df.dropna(subset=['Address'])\n",
    "#validate changes\n",
    "df.info()\n",
    "\n",
    "#drop irelevant columns\n",
    "variables_remove = [\"List Year\", \"Property Type\", \"Non Use Code\", \"Assessor Remarks\", \"OPM remarks\", \"Location\"]\n",
    "df = df.drop(columns=variables_remove)\n",
    "#validate changes\n",
    "df.info()\n",
    "\n",
    "#data cleaning pipline\n",
    "df_cleaned = df[\n",
    "    (df['Town'] != \"***Unknown***\") &\n",
    "    (df['Sale Amount'] > 30000)\n",
    "].copy()\n",
    "#change date format\n",
    "df_cleaned.loc[:, 'Date Recorded'] = pd.to_datetime(df_cleaned['Date Recorded'], format='%m/%d/%Y').dt.strftime('%Y-%m-%d')\n",
    "#validate changes\n",
    "df_cleaned.head()\n",
    "df_cleaned.info()\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Randomly assign status\n",
    "statuses = np.random.choice(\n",
    "    ['SOLD', 'LEASED', 'PENDING'],\n",
    "    size=len(df_cleaned),\n",
    "    p=[0.7, 0.2, 0.1]\n",
    ")\n",
    "\n",
    "df_cleaned['Status'] = statuses\n",
    "\n",
    "# Set sale_amount and sales_ratio to NULL for LEASED and PENDING\n",
    "df_cleaned.loc[df_cleaned['Status'].isin(['LEASED', 'PENDING']), ['Sale Amount', 'Sales Ratio']] = None\n",
    "df_cleaned['State'] = 'CT'\n",
    "#remove outlier and ensure null value for LEASED and PENDING status are inserted\n",
    "df_cleaned = df_cleaned[df_cleaned['Sale Amount'].isnull() | (df_cleaned['Sale Amount'] < 10**8)]\n",
    "df_cleaned = df_cleaned[df_cleaned['Assessed Value'].isnull() | (df_cleaned['Assessed Value'] < 10**8)]\n",
    "#validate changes\n",
    "df_cleaned.info()\n",
    "\n",
    "# Limit the DataFrame to 1000 rows\n",
    "df_cleaned = df_cleaned.head(1000)\n",
    "\n",
    "#Data insertion\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection parameters\n",
    "db_url = \"postgresql+psycopg2://postgres:111@localhost:5432/0802\"\n",
    "engine = create_engine(db_url)\n",
    "conn = engine.connect()\n",
    "\n",
    "\n",
    "# Rename columns in the DataFrame for insertion\n",
    "df_cleaned = df_cleaned.rename(columns={\n",
    "    'Serial Number': 'home_id',\n",
    "    'Address': 'address',\n",
    "    'Town': 'city',\n",
    "    'State': 'state',\n",
    "    'Date Recorded': 'date_recorded',\n",
    "    'Assessed Value': 'assessed_value',\n",
    "    'Sale Amount': 'sale_amount',\n",
    "    'Sales Ratio': 'sales_ratio',\n",
    "    'Residential Type': 'type',\n",
    "    'Status': 'status'\n",
    "})\n",
    "\n",
    "# Insert data into Homes\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO Homes (home_id, address, city, state, date_recorded, assessed_value, sale_amount, sales_ratio, type, status)\n",
    "VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "ON CONFLICT (home_id) DO NOTHING;\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    for index, row in df_cleaned.iterrows():\n",
    "        conn.execute(insert_query, (\n",
    "            row['home_id'],\n",
    "            row['address'],\n",
    "            row['city'],\n",
    "            row['state'],\n",
    "            row['date_recorded'],\n",
    "            row['assessed_value'],\n",
    "            row['sale_amount'],\n",
    "            row['sales_ratio'],\n",
    "            row['type'],\n",
    "            row['status']\n",
    "        ))\n",
    "    conn.execute(\"COMMIT\")\n",
    "    print(\"Data loaded successfully into the Homes table.\")\n",
    "except Exception as e:\n",
    "    conn.execute(\"ROLLBACK\")\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n"
   ],
   "metadata": {
    "id": "pUEhnqVCNi07",
    "ExecuteTime": {
     "end_time": "2024-08-07T04:15:26.157499Z",
     "start_time": "2024-08-07T04:15:23.398722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 997213 entries, 0 to 997212\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   Serial Number     997213 non-null  int64  \n",
      " 1   List Year         997213 non-null  int64  \n",
      " 2   Date Recorded     997211 non-null  object \n",
      " 3   Town              997213 non-null  object \n",
      " 4   Address           997162 non-null  object \n",
      " 5   Assessed Value    997213 non-null  float64\n",
      " 6   Sale Amount       997213 non-null  float64\n",
      " 7   Sales Ratio       997213 non-null  float64\n",
      " 8   Property Type     614767 non-null  object \n",
      " 9   Residential Type  608904 non-null  object \n",
      " 10  Non Use Code      289681 non-null  object \n",
      " 11  Assessor Remarks  149864 non-null  object \n",
      " 12  OPM remarks       9934 non-null    object \n",
      " 13  Location          197697 non-null  object \n",
      "dtypes: float64(3), int64(2), object(9)\n",
      "memory usage: 106.5+ MB\n",
      "The total NA value in Date Recorded:  2\n",
      "The total NA value in Address:  51\n",
      "The total NA value in Residential Type:  388309\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 608900 entries, 1 to 997211\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   Serial Number     608900 non-null  int64  \n",
      " 1   List Year         608900 non-null  int64  \n",
      " 2   Date Recorded     608900 non-null  object \n",
      " 3   Town              608900 non-null  object \n",
      " 4   Address           608900 non-null  object \n",
      " 5   Assessed Value    608900 non-null  float64\n",
      " 6   Sale Amount       608900 non-null  float64\n",
      " 7   Sales Ratio       608900 non-null  float64\n",
      " 8   Property Type     608900 non-null  object \n",
      " 9   Residential Type  608900 non-null  object \n",
      " 10  Non Use Code      182397 non-null  object \n",
      " 11  Assessor Remarks  125626 non-null  object \n",
      " 12  OPM remarks       9022 non-null    object \n",
      " 13  Location          123755 non-null  object \n",
      "dtypes: float64(3), int64(2), object(9)\n",
      "memory usage: 69.7+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 608900 entries, 1 to 997211\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   Serial Number     608900 non-null  int64  \n",
      " 1   Date Recorded     608900 non-null  object \n",
      " 2   Town              608900 non-null  object \n",
      " 3   Address           608900 non-null  object \n",
      " 4   Assessed Value    608900 non-null  float64\n",
      " 5   Sale Amount       608900 non-null  float64\n",
      " 6   Sales Ratio       608900 non-null  float64\n",
      " 7   Residential Type  608900 non-null  object \n",
      "dtypes: float64(3), int64(1), object(4)\n",
      "memory usage: 41.8+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 596494 entries, 1 to 997211\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   Serial Number     596494 non-null  int64  \n",
      " 1   Date Recorded     596494 non-null  object \n",
      " 2   Town              596494 non-null  object \n",
      " 3   Address           596494 non-null  object \n",
      " 4   Assessed Value    596494 non-null  float64\n",
      " 5   Sale Amount       596494 non-null  float64\n",
      " 6   Sales Ratio       596494 non-null  float64\n",
      " 7   Residential Type  596494 non-null  object \n",
      "dtypes: float64(3), int64(1), object(4)\n",
      "memory usage: 41.0+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 596489 entries, 1 to 997211\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   Serial Number     596489 non-null  int64  \n",
      " 1   Date Recorded     596489 non-null  object \n",
      " 2   Town              596489 non-null  object \n",
      " 3   Address           596489 non-null  object \n",
      " 4   Assessed Value    596489 non-null  float64\n",
      " 5   Sale Amount       418257 non-null  float64\n",
      " 6   Sales Ratio       418257 non-null  float64\n",
      " 7   Residential Type  596489 non-null  object \n",
      " 8   Status            596489 non-null  object \n",
      " 9   State             596489 non-null  object \n",
      "dtypes: float64(3), int64(1), object(6)\n",
      "memory usage: 50.1+ MB\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'psycopg2'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 67\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;66;03m# Database connection parameters\u001B[39;00m\n\u001B[0;32m     66\u001B[0m db_url \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpostgresql+psycopg2://postgres:111@localhost:5432/0802\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 67\u001B[0m engine \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdb_url\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     68\u001B[0m conn \u001B[38;5;241m=\u001B[39m engine\u001B[38;5;241m.\u001B[39mconnect()\n\u001B[0;32m     71\u001B[0m \u001B[38;5;66;03m# Rename columns in the DataFrame for insertion\u001B[39;00m\n",
      "File \u001B[1;32m<string>:2\u001B[0m, in \u001B[0;36mcreate_engine\u001B[1;34m(url, **kwargs)\u001B[0m\n",
      "File \u001B[1;32mD:\\pythonProject\\demo0708\\.venv\\Lib\\site-packages\\sqlalchemy\\util\\deprecations.py:281\u001B[0m, in \u001B[0;36mdeprecated_params.<locals>.decorate.<locals>.warned\u001B[1;34m(fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m    274\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m kwargs:\n\u001B[0;32m    275\u001B[0m         _warn_with_version(\n\u001B[0;32m    276\u001B[0m             messages[m],\n\u001B[0;32m    277\u001B[0m             versions[m],\n\u001B[0;32m    278\u001B[0m             version_warnings[m],\n\u001B[0;32m    279\u001B[0m             stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m,\n\u001B[0;32m    280\u001B[0m         )\n\u001B[1;32m--> 281\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\pythonProject\\demo0708\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\create.py:599\u001B[0m, in \u001B[0;36mcreate_engine\u001B[1;34m(url, **kwargs)\u001B[0m\n\u001B[0;32m    597\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m kwargs:\n\u001B[0;32m    598\u001B[0m             dbapi_args[k] \u001B[38;5;241m=\u001B[39m pop_kwarg(k)\n\u001B[1;32m--> 599\u001B[0m     dbapi \u001B[38;5;241m=\u001B[39m \u001B[43mdbapi_meth\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdbapi_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    601\u001B[0m dialect_args[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdbapi\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m dbapi\n\u001B[0;32m    603\u001B[0m dialect_args\u001B[38;5;241m.\u001B[39msetdefault(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompiler_linting\u001B[39m\u001B[38;5;124m\"\u001B[39m, compiler\u001B[38;5;241m.\u001B[39mNO_LINTING)\n",
      "File \u001B[1;32mD:\\pythonProject\\demo0708\\.venv\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\psycopg2.py:690\u001B[0m, in \u001B[0;36mPGDialect_psycopg2.import_dbapi\u001B[1;34m(cls)\u001B[0m\n\u001B[0;32m    688\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[0;32m    689\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mimport_dbapi\u001B[39m(\u001B[38;5;28mcls\u001B[39m):\n\u001B[1;32m--> 690\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpsycopg2\u001B[39;00m\n\u001B[0;32m    692\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m psycopg2\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'psycopg2'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "#### Schools\n",
    "\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a Faker instance\n",
    "fake = Faker()\n",
    "\n",
    "# Generate data for 100 schools\n",
    "school_data = {\n",
    "    'school_id': [i for i in range(1, 101)],\n",
    "    'address': [fake.street_address() for _ in range(100)],\n",
    "    'city': [fake.city() for _ in range(100)],\n",
    "    'state': [fake.state_abbr() for _ in range(100)],\n",
    "    'zip_code': [fake.zipcode() for _ in range(100)]\n",
    "}\n",
    "\n",
    "df_schools = pd.DataFrame(school_data)\n",
    "\n",
    "# Create the Schools table\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Schools (\n",
    "    school_id INT PRIMARY KEY,\n",
    "    address VARCHAR(255),\n",
    "    city VARCHAR(100),\n",
    "    state VARCHAR(50),\n",
    "    zip_code VARCHAR(10)\n",
    ");\n",
    "\"\"\"\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(create_table_query)\n",
    "\n",
    "# Insert data into the Schools table\n",
    "try:\n",
    "    df_schools.to_sql('Schools', engine, if_exists='append', index=False)\n",
    "    print(\"100 rows of school data inserted successfully into the Schools table.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Add school_id column to Homes table\n",
    "alter_table_query = \"\"\"\n",
    "ALTER TABLE Homes\n",
    "ADD COLUMN school_id INT,\n",
    "ADD FOREIGN KEY (school_id) REFERENCES Schools(school_id);\n",
    "\"\"\"\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(alter_table_query)\n",
    "    print(\"Added school_id column to Homes table.\")\n",
    "\n",
    "# Randomly assign school_id to homes\n",
    "df_homes = pd.read_sql_table('Homes', con=engine)\n",
    "df_homes['school_id'] = np.random.choice(df_schools['school_id'], size=len(df_homes))\n",
    "\n",
    "update_query = \"\"\"\n",
    "UPDATE Homes\n",
    "SET school_id = %s\n",
    "WHERE home_id = %s;\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        for index, row in df_homes.iterrows():\n",
    "            connection.execute(update_query, (row['school_id'], row['home_id']))\n",
    "        connection.execute(\"COMMIT\")\n",
    "        print(\"school_id values updated in the Homes table.\")\n",
    "except Exception as e:\n",
    "    connection.execute(\"ROLLBACK\")\n",
    "    print(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "    connection.close()\n"
   ],
   "metadata": {
    "id": "ogD1VAqXS6Kl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#### Clients\n",
    "\n",
    "# Generate data for 1000 clients\n",
    "client_data = {\n",
    "    'client_id': [i for i in range(1, 1001)],\n",
    "    'first_name': [fake.first_name() for _ in range(1000)],\n",
    "    'last_name': [fake.last_name() for _ in range(1000)],\n",
    "    'email': [fake.email() for _ in range(1000)],\n",
    "    'phone_number': [fake.phone_number() for _ in range(1000)],\n",
    "    'client_type': [fake.random_element(elements=('Individual', 'Company')) for _ in range(1000)]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df_clients = pd.DataFrame(client_data)\n",
    "\n",
    "# Create the Clients table\n",
    "create_clients_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Clients (\n",
    "    client_id INT PRIMARY KEY,\n",
    "    first_name VARCHAR(100),\n",
    "    last_name VARCHAR(100),\n",
    "    email VARCHAR(100),\n",
    "    phone_number VARCHAR(15),\n",
    "    client_type VARCHAR(50)\n",
    ");\n",
    "\"\"\"\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(create_clients_table_query)\n",
    "\n",
    "# Insert data into the Clients table\n",
    "try:\n",
    "    df_clients.to_sql('Clients', engine, if_exists='append', index=False)\n",
    "    print(\"1000 rows of client data inserted successfully into the Clients table.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ],
   "metadata": {
    "id": "kb6ZBRYBWc_Y"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#### ClientPreferences\n",
    "\n",
    "# Generate data for 5000 client preferences\n",
    "preference_data = {\n",
    "    'preference_id': [i for i in range(1, 5001)],\n",
    "    'client_id': [fake.random_int(min=1, max=1000) for _ in range(5000)],\n",
    "    'preference_type': [fake.random_element(elements=('Color', 'Size', 'Brand', 'Category')) for _ in range(5000)],\n",
    "    'value': [fake.word() for _ in range(5000)]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df_preferences = pd.DataFrame(preference_data)\n",
    "\n",
    "# Create the ClientPreferences table\n",
    "create_preferences_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS ClientPreferences (\n",
    "    preference_id INT PRIMARY KEY,\n",
    "    client_id INT,\n",
    "    preference_type VARCHAR(50),\n",
    "    value VARCHAR(255),\n",
    "    FOREIGN KEY (client_id) REFERENCES Clients(client_id)\n",
    ");\n",
    "\"\"\"\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(create_preferences_table_query)\n",
    "\n",
    "# Insert data into the ClientPreferences table\n",
    "try:\n",
    "    df_preferences.to_sql('ClientPreferences', engine, if_exists='append', index=False)\n",
    "    print(\"5000 rows of client preference data inserted successfully into the ClientPreferences table.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ],
   "metadata": {
    "id": "XlLQ9o0-XpQb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#### Employees\n",
    "\n",
    "# Generate data for 100 employees\n",
    "employee_data = {\n",
    "    'employee_id': [i for i in range(1, 101)],\n",
    "    'first_name': [fake.first_name() for _ in range(100)],\n",
    "    'last_name': [fake.last_name() for _ in range(100)],\n",
    "    'email': [fake.email() for _ in range(100)],\n",
    "    'phone_number': [fake.phone_number() for _ in range(100)],\n",
    "    'employment_type': [fake.random_element(elements=('Full-Time', 'Part-Time', 'Contract', 'Temporary')) for _ in range(100)]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df_employees = pd.DataFrame(employee_data)\n",
    "\n",
    "# Create the Employees table\n",
    "create_employees_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Employees (\n",
    "    employee_id INT PRIMARY KEY,\n",
    "    first_name VARCHAR(100),\n",
    "    last_name VARCHAR(100),\n",
    "    email VARCHAR(100),\n",
    "    phone_number VARCHAR(15),\n",
    "    employment_type VARCHAR(50)\n",
    ");\n",
    "\"\"\"\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(create_employees_table_query)\n",
    "\n",
    "# Insert data into the Employees table\n",
    "try:\n",
    "    df_employees.to_sql('Employees', engine, if_exists='append', index=False)\n",
    "    print(\"100 rows of employee data inserted successfully into the Employees table.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ],
   "metadata": {
    "id": "9kD255YCXpa2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#### Owners\n",
    "\n",
    "# Generate data for 1000 owners\n",
    "owners_data = {\n",
    "    'owner_id': [i for i in range(1, 1001)],\n",
    "    'first_name': [fake.first_name() for _ in range(1000)],\n",
    "    'last_name': [fake.last_name() for _ in range(1000)],\n",
    "    'email': [fake.email() for _ in range(1000)],\n",
    "    'phone_number': [fake.phone_number() for _ in range(1000)]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df_owners = pd.DataFrame(owners_data)\n",
    "\n",
    "# Create the Owners table\n",
    "create_owners_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Owners (\n",
    "    owner_id INT PRIMARY KEY,\n",
    "    first_name VARCHAR(100),\n",
    "    last_name VARCHAR(100),\n",
    "    email VARCHAR(100),\n",
    "    phone_number VARCHAR(15)\n",
    ");\n",
    "\"\"\"\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(create_owners_table_query)\n",
    "\n",
    "# Insert data into the Owners table\n",
    "try:\n",
    "    df_owners.to_sql('Owners', engine, if_exists='append', index=False)\n",
    "    print(\"1000 rows of owners data inserted successfully into the Owners table.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ],
   "metadata": {
    "id": "8aW7fvhLcq1Y"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#### TransactionTypes\n",
    "\n",
    "# Data for TransactionsTypes\n",
    "transaction_types_data = {\n",
    "    'transaction_type_id': [i for i in range(1, 6)],\n",
    "    'transaction_type_name': ['Purchase', 'Lease', 'Sale', 'Rent', 'Mortgage'],\n",
    "    'description': [fake.text(max_nb_chars=200) for _ in range(5)]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df_transaction_types = pd.DataFrame(transaction_types_data)\n",
    "\n",
    "# Create the TransactionsTypes table\n",
    "create_transaction_types_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS TransactionsTypes (\n",
    "    transaction_type_id INT PRIMARY KEY,\n",
    "    transaction_type_name VARCHAR(50),\n",
    "    description TEXT\n",
    ");\n",
    "\"\"\"\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(create_transaction_types_table_query)\n",
    "\n",
    "# Insert data into the TransactionsTypes table\n",
    "try:\n",
    "    df_transaction_types.to_sql('TransactionsTypes', engine, if_exists='append', index=False)\n",
    "    print(\"5 rows of transaction types data inserted successfully into the TransactionsTypes table.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ],
   "metadata": {
    "id": "U9NkYdUMYPlv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#### Transactions\n",
    "\n",
    "# Generate data for 400 transactions\n",
    "transaction_data = {\n",
    "    'transaction_id': [i for i in range(1, 401)],\n",
    "    'home_id': [fake.random_int(min=1, max=500) for _ in range(400)],\n",
    "    'buyer_id': [fake.random_int(min=1, max=1000) for _ in range(400)],\n",
    "    'owner_id': [fake.random_int(min=1, max=1000) for _ in range(400)],\n",
    "    'agent_id': [fake.random_int(min=1, max=100) for _ in range(400)],\n",
    "    'transaction_type_id': [fake.random_int(min=1, max=5) for _ in range(400)],\n",
    "    'date': [fake.date_between(start_date='-2y', end_date='today') for _ in range(400)],\n",
    "    'amount': [round(random.uniform(10000, 1000000), 2) for _ in range(400)]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df_transactions = pd.DataFrame(transaction_data)\n",
    "\n",
    "# Create the Transactions table\n",
    "create_transactions_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Transactions (\n",
    "    transaction_id INT PRIMARY KEY,\n",
    "    home_id INT,\n",
    "    buyer_id INT,\n",
    "    owner_id INT,\n",
    "    agent_id INT,\n",
    "    transaction_type_id INT,\n",
    "    date DATE,\n",
    "    amount DECIMAL(10, 2),\n",
    "    FOREIGN KEY (home_id) REFERENCES Homes(home_id),\n",
    "    FOREIGN KEY (buyer_id) REFERENCES Clients(client_id),\n",
    "    FOREIGN KEY (owner_id) REFERENCES Owners(owner_id),\n",
    "    FOREIGN KEY (agent_id) REFERENCES Employees(employee_id),\n",
    "    FOREIGN KEY (transaction_type_id) REFERENCES TransactionsTypes(transaction_type_id)\n",
    ");\n",
    "\"\"\"\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(create_transactions_table_query)\n",
    "\n",
    "# Insert data into the Transactions table\n",
    "try:\n",
    "    df_transactions.to_sql('Transactions', engine, if_exists='append', index=False)\n",
    "    print(\"400 rows of transaction data inserted successfully into the Transactions table.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ],
   "metadata": {
    "id": "E_RDKVhoYPsA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#### PaymentMethods\n",
    "\n",
    "# Data for PaymentMethods\n",
    "payment_methods_data = {\n",
    "    'payment_method_id': [i for i in range(1, 6)],\n",
    "    'method_name': ['Credit Card', 'Bank Transfer', 'Cash', 'Check', 'Cryptocurrency'],\n",
    "    'description': [fake.text(max_nb_chars=200) for _ in range(5)]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df_payment_methods = pd.DataFrame(payment_methods_data)\n",
    "\n",
    "# Create the PaymentMethods table\n",
    "create_payment_methods_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS PaymentMethods (\n",
    "    payment_method_id INT PRIMARY KEY,\n",
    "    method_name VARCHAR(50),\n",
    "    description TEXT\n",
    ");\n",
    "\"\"\"\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(create_payment_methods_table_query)\n",
    "\n",
    "# Insert data into the PaymentMethods table\n",
    "try:\n",
    "    df_payment_methods.to_sql('PaymentMethods', engine, if_exists='append', index=False)\n",
    "    print(\"5 rows of payment methods data inserted successfully into the PaymentMethods table.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ],
   "metadata": {
    "id": "Bw66w_InYPyb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#### TransactionPayments\n",
    "\n",
    "# Generate data for 400 transaction payments\n",
    "transaction_payments_data = {\n",
    "    'payment_id': [i for i in range(1, 401)],\n",
    "    'transaction_id': [fake.random_int(min=1, max=400) for _ in range(400)],\n",
    "    'payment_method_id': [fake.random_int(min=1, max=5) for _ in range(400)],\n",
    "    'amount': [round(random.uniform(10000, 1000000), 2) for _ in range(400)],\n",
    "    'date': [fake.date_between(start_date='-2y', end_date='today') for _ in range(400)]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df_transaction_payments = pd.DataFrame(transaction_payments_data)\n",
    "\n",
    "# Create the TransactionPayments table\n",
    "create_transaction_payments_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS TransactionPayments (\n",
    "    payment_id INT PRIMARY KEY,\n",
    "    transaction_id INT,\n",
    "    payment_method_id INT,\n",
    "    amount DECIMAL(10, 2),\n",
    "    date DATE,\n",
    "    FOREIGN KEY (transaction_id) REFERENCES Transactions(transaction_id),\n",
    "    FOREIGN KEY (payment_method_id) REFERENCES PaymentMethods(payment_method_id)\n",
    ");\n",
    "\"\"\"\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(create_transaction_payments_table_query)\n",
    "\n",
    "# Insert data into the TransactionPayments table\n",
    "try:\n",
    "    df_transaction_payments.to_sql('TransactionPayments', engine, if_exists='append', index=False)\n",
    "    print(\"400 rows of transaction payments data inserted successfully into the TransactionPayments table.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ],
   "metadata": {
    "id": "ZWD1XkEranmH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pip install pandas sqlalchemy faker"
   ],
   "metadata": {
    "id": "VEilGD8Eantj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Office:\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite:///offices.db', echo=True)\n",
    "\n",
    "# generate office data\n",
    "office_data = {\n",
    "    'office_id': [1, 2, 3, 4, 5],\n",
    "    'address': ['123 Broadway', '456 Fifth Ave', '789 Wall St', '101 Park Ave', '202 Madison Ave'],\n",
    "    'city': ['New York'] * 5,\n",
    "    'state': ['NY'] * 5,\n",
    "    'zip_code': ['10001', '10010', '10005', '10178', '10016'],\n",
    "    'phone_number': ['212-555-0101', '212-555-0112', '212-555-0123', '212-555-0134', '212-555-0145']\n",
    "}\n",
    "\n",
    "df_offices = pd.DataFrame(office_data)\n",
    "\n",
    "# create offices table\n",
    "create_offices_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Offices (\n",
    "    office_id INT PRIMARY KEY,\n",
    "    address VARCHAR(255),\n",
    "    city VARCHAR(100),\n",
    "    state VARCHAR(50),\n",
    "    zip_code VARCHAR(10),\n",
    "    phone_number VARCHAR(15)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(create_offices_table_query)\n",
    "\n",
    "# insert data\n",
    "try:\n",
    "    df_offices.to_sql('Offices', engine, if_exists='append', index=False)\n",
    "    print(\"5 rows of office data inserted successfully into the Offices table.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ],
   "metadata": {
    "id": "CYw0QFgETU21"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Expenses:\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "engine = create_engine('sqlite:///offices.db', echo=True)\n",
    "\n",
    "# generate 1000 date for Expenses table\n",
    "fake = Faker()\n",
    "expense_data = {\n",
    "    'expense_id': [i for i in range(1, 1001)],\n",
    "    'description': [fake.sentence(nb_words=3) for _ in range(1000)],\n",
    "    'amount': [round(random.uniform(100.0, 5000.0), 2) for _ in range(1000)],\n",
    "    'date': [fake.date_this_year() for _ in range(1000)],\n",
    "    'office_id': [random.choice([1, 2, 3, 4, 5]) for _ in range(1000)]\n",
    "}\n",
    "\n",
    "df_expenses = pd.DataFrame(expense_data)\n",
    "\n",
    "# create Expenses table\n",
    "create_expenses_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Expenses (\n",
    "    expense_id INT PRIMARY KEY,\n",
    "    description TEXT,\n",
    "    amount DECIMAL(10, 2),\n",
    "    date DATE,\n",
    "    office_id INT,\n",
    "    FOREIGN KEY (office_id) REFERENCES Offices(office_id)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(create_expenses_table_query)\n",
    "\n",
    "# insert into expenses table\n",
    "try:\n",
    "    df_expenses.to_sql('Expenses', engine, if_exists='append', index=False)\n",
    "    print(\"1000 rows of expense data inserted successfully into the Expenses table.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ],
   "metadata": {
    "id": "0GA828PmTaXL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# EmployeeAssignment\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "engine = create_engine('sqlite:///offices.db', echo=True)\n",
    "\n",
    "# use Faker to generate 125 EmployeeOfficeAssignments data\n",
    "fake = Faker()\n",
    "assignment_data = {\n",
    "    'assignment_id': [i for i in range(1, 126)],\n",
    "    'employee_id': [random.randint(1, 100) for _ in range(125)],  # 假设有100个员工\n",
    "    'office_id': [random.choice([1, 2, 3, 4, 5]) for _ in range(125)],\n",
    "    'start_date': [fake.date_between(start_date='-2y', end_date='today') for _ in range(125)],\n",
    "    'end_date': [fake.date_between(start_date='today', end_date='+1y') for _ in range(125)]\n",
    "}\n",
    "\n",
    "df_assignments = pd.DataFrame(assignment_data)\n",
    "\n",
    "# create EmployeeOfficeAssignments table\n",
    "create_assignments_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS EmployeeOfficeAssignments (\n",
    "    assignment_id INT PRIMARY KEY,\n",
    "    employee_id INT,\n",
    "    office_id INT,\n",
    "    start_date DATE,\n",
    "    end_date DATE,\n",
    "    FOREIGN KEY (employee_id) REFERENCES Employees(employee_id),\n",
    "    FOREIGN KEY (office_id) REFERENCES Offices(office_id)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(create_assignments_table_query)\n",
    "\n",
    "# insert into EmployeeOfficeAssignments table\n",
    "try:\n",
    "    df_assignments.to_sql('EmployeeOfficeAssignments', engine, if_exists='append', index=False)\n",
    "    print(\"125 rows of assignment data inserted successfully into the EmployeeOfficeAssignments table.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ],
   "metadata": {
    "id": "DARemPeMTfJ_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#  Emolyee role:\n",
    "1. 创建 EmployeeRoles 表并插入角色数据\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import random\n",
    "\n",
    "engine = create_engine('sqlite:///offices.db', echo=True)\n",
    "\n",
    "create_employee_roles_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS EmployeeRoles (\n",
    "    role_id INT PRIMARY KEY,\n",
    "    role_name VARCHAR(50),\n",
    "    description TEXT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(create_employee_roles_table_query)\n",
    "\n",
    "# create fixed roles\n",
    "role_data = {\n",
    "    'role_id': [1, 2, 3],\n",
    "    'role_name': ['Associate', 'Senior', 'Manager'],\n",
    "    'description': ['Entry level position', 'Experienced professional', 'Management position']\n",
    "}\n",
    "\n",
    "df_roles = pd.DataFrame(role_data)\n",
    "\n",
    "# insert into EmployeeRoles table\n",
    "try:\n",
    "    df_roles.to_sql('EmployeeRoles', engine, if_exists='append', index=False)\n",
    "    print(\"3 rows of role data inserted successfully into the EmployeeRoles table.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# add role_id attribute to Employees table\n",
    "alter_employees_table_query = \"\"\"\n",
    "ALTER TABLE Employees\n",
    "ADD COLUMN role_id INT,\n",
    "ADD FOREIGN KEY (role_id) REFERENCES EmployeeRoles(role_id);\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(alter_employees_table_query)\n",
    "\n",
    "# randomly assign roles to employees\n",
    "employee_role_data = {\n",
    "    'employee_id': [i for i in range(1, 101)],\n",
    "    'role_id': [random.choice([1, 2, 3]) for _ in range(100)]\n",
    "}\n",
    "\n",
    "df_employee_roles = pd.DataFrame(employee_role_data)\n",
    "\n",
    "\n",
    "#update roles\n",
    "with engine.connect() as connection:\n",
    "    for index, row in df_employee_roles.iterrows():\n",
    "        update_query = f\"\"\"\n",
    "        UPDATE Employees\n",
    "        SET role_id = {row['role_id']}\n",
    "        WHERE employee_id = {row['employee_id']};\n",
    "        \"\"\"\n",
    "        connection.execute(update_query)\n"
   ],
   "metadata": {
    "id": "etWYIqblTi5x"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Marketingcampagin&campaign results\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "engine = create_engine('sqlite:///marketing.db', echo=True)\n",
    "\n",
    "create_marketing_campaigns_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS MarketingCampaigns (\n",
    "    campaign_id INT PRIMARY KEY,\n",
    "    campaign_name VARCHAR(100),\n",
    "    description TEXT,\n",
    "    start_date DATE,\n",
    "    end_date DATE,\n",
    "    budget DECIMAL(10, 2)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "create_campaign_results_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS CampaignResults (\n",
    "    result_id INT PRIMARY KEY,\n",
    "    campaign_id INT,\n",
    "    result_description TEXT,\n",
    "    result_date DATE,\n",
    "    FOREIGN KEY (campaign_id) REFERENCES MarketingCampaigns(campaign_id)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(create_marketing_campaigns_table_query)\n",
    "    connection.execute(create_campaign_results_table_query)\n",
    "\n",
    "print(\"Tables created successfully.\")\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "campaign_data = {\n",
    "    'campaign_id': [i for i in range(1, 21)],\n",
    "    'campaign_name': [fake.company() for _ in range(20)],\n",
    "    'description': [fake.text(max_nb_chars=200) for _ in range(20)],\n",
    "    'start_date': [fake.date_between(start_date='-2y', end_date='-1y') for _ in range(20)],\n",
    "    'end_date': [fake.date_between(start_date='-1y', end_date='today') for _ in range(20)],\n",
    "    'budget': [round(random.uniform(1000, 100000), 2) for _ in range(20)]\n",
    "}\n",
    "\n",
    "df_campaigns = pd.DataFrame(campaign_data)\n",
    "\n",
    "try:\n",
    "    df_campaigns.to_sql('MarketingCampaigns', engine, if_exists='append', index=False)\n",
    "    print(\"20 rows of campaign data inserted successfully into the MarketingCampaigns table.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "result_data = {\n",
    "    'result_id': [i for i in range(1, 21)],\n",
    "    'campaign_id': [random.choice([i for i in range(1, 21)]) for _ in range(20)],\n",
    "    'result_description': [fake.text(max_nb_chars=200) for _ in range(20)],\n",
    "    'result_date': [fake.date_between(start_date='-1y', end_date='today') for _ in range(20)]\n",
    "}\n",
    "\n",
    "df_results = pd.DataFrame(result_data)\n",
    "\n",
    "# insert into CampaignResults\n",
    "try:\n",
    "    df_results.to_sql('CampaignResults', engine, if_exists='append', index=False)\n",
    "    print(\"20 rows of result data inserted successfully into the CampaignResults table.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ],
   "metadata": {
    "id": "YMTnsUeSTucZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Payment method:\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "engine = create_engine('sqlite:///realestate.db', echo=True)\n",
    "\n",
    "\n",
    "create_payment_methods_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS PaymentMethods (\n",
    "    payment_method_id INT PRIMARY KEY,\n",
    "    method_name VARCHAR(50),\n",
    "    description TEXT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(create_payment_methods_table_query)\n",
    "\n",
    "print(\"PaymentMethods table created successfully.\")\n",
    "\n",
    "# fixed payment method types\n",
    "payment_methods_data = {\n",
    "    'payment_method_id': [1, 2, 3, 4, 5],\n",
    "    'method_name': ['Credit Card', 'Debit Card', 'Bank Transfer', 'Cash', 'PayPal'],\n",
    "    'description': [\n",
    "        'Payment made using credit card',\n",
    "        'Payment made using debit card',\n",
    "        'Payment made through bank transfer',\n",
    "        'Payment made in cash',\n",
    "        'Payment made using PayPal'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_payment_methods = pd.DataFrame(payment_methods_data)\n",
    "\n",
    "# insert into PaymentMethods\n",
    "try:\n",
    "    df_payment_methods.to_sql('PaymentMethods', engine, if_exists='append', index=False)\n",
    "    print(\"5 rows of payment methods data inserted successfully into the PaymentMethods table.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# randomly generate 400 TransactionPayments sample data\n",
    "transaction_payments_data = {\n",
    "    'payment_id': [i for i in range(1, 401)],\n",
    "    'transaction_id': [fake.random_int(min=1, max=400) for _ in range(400)],\n",
    "    'payment_method_id': [fake.random_int(min=1, max=5) for _ in range(400)],\n",
    "    'amount': [round(random.uniform(10000, 1000000), 2) for _ in range(400)],\n",
    "    'date': [fake.date_between(start_date='-2y', end_date='today') for _ in range(400)]\n",
    "}\n",
    "\n",
    "df_transaction_payments = pd.DataFrame(transaction_payments_data)\n",
    "\n",
    "# insert into TransactionPayments\n",
    "try:\n",
    "    df_transaction_payments.to_sql('TransactionPayments', engine, if_exists='append', index=False)\n",
    "    print(\"400 rows of transaction payments data inserted successfully into the TransactionPayments table.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n"
   ],
   "metadata": {
    "id": "WQwyYP-ET0W7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# HomefeatureAssignments& HomeFeatures:\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "engine = create_engine('sqlite:///realestate.db', echo=True)\n",
    "\n",
    "create_home_features_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS HomeFeatures (\n",
    "    feature_id INT PRIMARY KEY,\n",
    "    feature_name VARCHAR(50),\n",
    "    description TEXT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(create_home_features_table_query)\n",
    "\n",
    "print(\"HomeFeatures table created successfully.\")\n",
    "\n",
    "# randomly generate 50 HomeFeatures sample data\n",
    "home_features_data = {\n",
    "    'feature_id': [i for i in range(1, 51)],\n",
    "    'feature_name': [fake.word().capitalize() for _ in range(50)],\n",
    "    'description': [fake.sentence() for _ in range(50)]\n",
    "}\n",
    "\n",
    "df_home_features = pd.DataFrame(home_features_data)\n",
    "\n",
    "try:\n",
    "    df_home_features.to_sql('HomeFeatures', engine, if_exists='append', index=False)\n",
    "    print(\"50 rows of home features data inserted successfully into the HomeFeatures table.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "create_home_feature_assignments_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS HomeFeatureAssignments (\n",
    "    assignment_id INT PRIMARY KEY,\n",
    "    home_id INT,\n",
    "    feature_id INT,\n",
    "    FOREIGN KEY (home_id) REFERENCES Homes(home_id),\n",
    "    FOREIGN KEY (feature_id) REFERENCES HomeFeatures(feature_id)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(create_home_feature_assignments_table_query)\n",
    "\n",
    "print(\"HomeFeatureAssignments table created successfully.\")\n",
    "\n",
    "# get existing home_id\n",
    "existing_home_ids_query = \"SELECT home_id FROM Homes\"\n",
    "with engine.connect() as connection:\n",
    "    existing_home_ids = [row['home_id'] for row in connection.execute(existing_home_ids_query)]\n",
    "\n",
    "# randomly generate 5000 HomeFeatureAssignments sample data\n",
    "home_feature_assignments_data = {\n",
    "    'assignment_id': [i for i in range(1, 5001)],\n",
    "    'home_id': [random.choice(existing_home_ids) for _ in range(5000)],\n",
    "    'feature_id': [random.randint(1, 50) for _ in range(5000)]\n",
    "}\n",
    "\n",
    "\n",
    "df_home_feature_assignments = pd.DataFrame(home_feature_assignments_data)\n",
    "\n",
    "# insert into HomeFeatureAssignments\n",
    "try:\n",
    "    df_home_feature_assignments.to_sql('HomeFeatureAssignments', engine, if_exists='append', index=False)\n",
    "    print(\"5000 rows of home feature assignments data inserted successfully into the HomeFeatureAssignments table.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ],
   "metadata": {
    "id": "e0ijwT7_T7S8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Openhouses:\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "engine = create_engine('sqlite:///realestate.db', echo=True)\n",
    "\n",
    "create_open_houses_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS OpenHouses (\n",
    "    open_house_id INT PRIMARY KEY,\n",
    "    home_id INT,\n",
    "    date DATE,\n",
    "    start_time TIME,\n",
    "    end_time TIME,\n",
    "    FOREIGN KEY (home_id) REFERENCES Homes(home_id)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(create_open_houses_table_query)\n",
    "\n",
    "print(\"OpenHouses table created successfully.\")\n",
    "\n",
    "# get existing home_id\n",
    "existing_home_ids_query = \"SELECT home_id FROM Homes\"\n",
    "with engine.connect() as connection:\n",
    "    existing_home_ids = [row['home_id'] for row in connection.execute(existing_home_ids_query)]\n",
    "\n",
    "\n",
    "def random_time():\n",
    "    \"\"\"Randomly generate time\"\"\"\n",
    "    return (datetime.min + timedelta(seconds=random.randint(0, 24 * 3600))).time()\n",
    "\n",
    "open_houses_data = {\n",
    "    'open_house_id': [i for i in range(1, 101)],\n",
    "    'home_id': [random.choice(existing_home_ids) for _ in range(100)],\n",
    "    'date': [fake.date_between(start_date='-1y', end_date='today') for _ in range(100)],\n",
    "    'start_time': [random_time() for _ in range(100)],\n",
    "    'end_time': [random_time() for _ in range(100)]\n",
    "}\n",
    "\n",
    "# ensure end_time is later than start_time\n",
    "df_open_houses = pd.DataFrame(open_houses_data)\n",
    "df_open_houses['end_time'] = df_open_houses.apply(\n",
    "    lambda row: row['end_time'] if row['end_time'] > row['start_time'] else (datetime.combine(datetime.min, row['start_time']) + timedelta(hours=1)).time(),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "try:\n",
    "    df_open_houses.to_sql('OpenHouses', engine, if_exists='append', index=False)\n",
    "    print(\"100 rows of open houses data inserted successfully into the OpenHouses table.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ],
   "metadata": {
    "id": "FNh8O_dcT_-Z"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Appointments:\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime, time\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "engine = create_engine('sqlite:///realestate.db', echo=True)\n",
    "\n",
    "create_appointments_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Appointments (\n",
    "    appointment_id INT PRIMARY KEY,\n",
    "    client_id INT,\n",
    "    employee_id INT,\n",
    "    home_id INT,\n",
    "    date DATE,\n",
    "    time TIME,\n",
    "    FOREIGN KEY (client_id) REFERENCES Clients(client_id),\n",
    "    FOREIGN KEY (employee_id) REFERENCES Employees(employee_id),\n",
    "    FOREIGN KEY (home_id) REFERENCES Homes(home_id)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(create_appointments_table_query)\n",
    "\n",
    "print(\"Appointments table created successfully.\")\n",
    "\n",
    "# get existing client_id, employee_id, and home_id\n",
    "existing_client_ids_query = \"SELECT client_id FROM Clients\"\n",
    "existing_employee_ids_query = \"SELECT employee_id FROM Employees\"\n",
    "existing_home_ids_query = \"SELECT home_id FROM Homes\"\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    existing_client_ids = [row['client_id'] for row in connection.execute(existing_client_ids_query)]\n",
    "    existing_employee_ids = [row['employee_id'] for row in connection.execute(existing_employee_ids_query)]\n",
    "    existing_home_ids = [row['home_id'] for row in connection.execute(existing_home_ids_query)]\n",
    "\n",
    "def random_time():\n",
    "    \"\"\"Randomly generate time\"\"\"\n",
    "    return (datetime.min + timedelta(seconds=random.randint(0, 24 * 3600))).time()\n",
    "\n",
    "appointments_data = {\n",
    "    'appointment_id': [i for i in range(1, 5001)],\n",
    "    'client_id': [random.choice(existing_client_ids) for _ in range(5000)],\n",
    "    'employee_id': [random.choice(existing_employee_ids) for _ in range(5000)],\n",
    "    'home_id': [random.choice(existing_home_ids) for _ in range(5000)],\n",
    "    'date': [fake.date_between(start_date='-1y', end_date='today') for _ in range(5000)],\n",
    "    'time': [random_time() for _ in range(5000)]\n",
    "}\n",
    "\n",
    "\n",
    "df_appointments = pd.DataFrame(appointments_data)\n",
    "\n",
    "\n",
    "try:\n",
    "    df_appointments.to_sql('Appointments', engine, if_exists='append', index=False)\n",
    "    print(\"5000 rows of appointments data inserted successfully into the Appointments table.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ],
   "metadata": {
    "id": "5JRiB-SQUDgx"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
